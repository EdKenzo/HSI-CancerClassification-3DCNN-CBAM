{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # HSI deeplearning FYP -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, utils\n",
    "import torchvision\n",
    "from torch.utils.data import ConcatDataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io \n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.signal import savgol_filter\n",
    "import pandas as pd #don't work with newest numpy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Quality control: Remove low intensity spectra, PCA (80), removing paraffin wax regions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pca(spectral_image, n_components=80):\n",
    "    \"\"\"\n",
    "    Apply PCA for noise reduction on a hyperspectral image.\n",
    "\n",
    "    Parameters:\n",
    "    spectral_image (numpy array): 3D array (H, W, C) representing spectral data\n",
    "    n_components (int): Number of principal components to retain\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Denoised spectral image (H, W, C)\n",
    "    \"\"\"\n",
    "    H, W, C = spectral_image.shape\n",
    "    reshaped_spectra = spectral_image.reshape(-1, C)  # Flatten to (H*W, C)\n",
    "\n",
    "    # Compute mean spectrum\n",
    "    mean_spectra = np.mean(reshaped_spectra, axis=0)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "    transformed = pca_model.fit_transform(reshaped_spectra - mean_spectra)  # Center data\n",
    "    denoised = pca_model.inverse_transform(transformed) + mean_spectra  # Reconstruct\n",
    "\n",
    "    # Reshape back to (H, W, C)\n",
    "    return denoised.reshape(H, W, C)\n",
    "\n",
    "\n",
    "def preprocess(spectral_image, wavenumbers):\n",
    "    \"\"\"\n",
    "    Preprocess a hyperspectral image with noise reduction and filtering.\n",
    "\n",
    "    Parameters:\n",
    "    spectral_image (numpy array): 3D array (H, W, C)\n",
    "    wavenumbers (numpy array): 1D array of spectral bands\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Preprocessed spectral image (H, W, filtered_C)\n",
    "    \"\"\"\n",
    "    H, W, C = spectral_image.shape\n",
    "\n",
    "    # 1. Quality filtering based on Amide I Band (1600 - 1700 cm⁻¹)\n",
    "    amide_band_indices = np.where((wavenumbers >= 1600) & (wavenumbers <= 1700))[0]\n",
    "    amide_spectra = np.max(spectral_image[:, :, amide_band_indices], axis=2)\n",
    "\n",
    "    # Retain pixels with valid absorbance (0.1 to 2)\n",
    "    valid_mask = (amide_spectra >= 0.1) & (amide_spectra <= 2)\n",
    "    \n",
    "    # Filter out invalid pixels (set spectra to zero where invalid)\n",
    "    filtered_spectral_image = spectral_image.copy()\n",
    "    filtered_spectral_image[~valid_mask] = 0  \n",
    "\n",
    "    # 2. Remove paraffin wax regions\n",
    "    valid_wavenumbers = (\n",
    "        ((wavenumbers >= 1000) & (wavenumbers <= 1319)) | \n",
    "        ((wavenumbers >= 1481) & (wavenumbers <= 1769)) |\n",
    "        ((wavenumbers >= 2986) & (wavenumbers <= 3569))\n",
    "    )\n",
    "\n",
    "    # Apply filtering to keep only valid wavenumbers\n",
    "    filtered_spectral_image = filtered_spectral_image[:, :, valid_wavenumbers]\n",
    "    filtered_wavenumbers = wavenumbers[valid_wavenumbers]\n",
    "\n",
    "    # 3. Compute First Derivative Using Savitzky-Golay Filter\n",
    "    window_size = 19  \n",
    "    poly_order = 4\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            filtered_spectral_image[i, j, :] = savgol_filter(filtered_spectral_image[i, j, :], window_length=window_size, polyorder=poly_order, deriv=1)\n",
    "\n",
    "    # 4. Remove Edge Regions Influenced by Derivatization\n",
    "    valid_end_regions = (\n",
    "        ((filtered_wavenumbers >= 1019) & (filtered_wavenumbers <= 1300)) |\n",
    "        ((filtered_wavenumbers >= 1500) & (filtered_wavenumbers <= 1750)) |\n",
    "        ((filtered_wavenumbers >= 3005) & (filtered_wavenumbers <= 3550))\n",
    "    )\n",
    "\n",
    "    final_spectral_image = filtered_spectral_image[:, :, valid_end_regions]\n",
    "    \n",
    "    return final_spectral_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing diff shape for 3D CNN deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# Define file locations\n",
    "data_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\DataCube\\DataCube_npz\"\n",
    "annotation_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\overlay\"\n",
    "\n",
    "core_names = [\n",
    "    \"A12\",\"C10\", \"C16\", \"C5\", \"C8\",\n",
    "    \"D5\", \"D7\", \"D8\", \"D9\", \"E7\", \"E8\", \"F5\", \"F7\", \"F8\",\n",
    "    \"G6\", \"H7\", \"H10\", \"H9\", \"I3\", \"I5\", \"A14\", \"I7\", \"B9\", \"I10\",\n",
    "    \"K1\", \"K10\", \"K6\", \"K9\", \"B11\", \"L10\", \"L2\", \"L3\",\n",
    "    \"M1\", \"M3\", \"M4\", \"M6\", \"M9\", \"M10\", \"M11\", \"M13\"\n",
    "]\n",
    "\n",
    "annotation_colours = {\n",
    "    \"red\": (255, 0, 0),      # Cancer\n",
    "    \"green\": (103, 193, 66), # Normal\n",
    "    \"orange\": (243, 143, 53),# Normal\n",
    "    \"purple\": (165, 55, 156) # Cancer\n",
    "}\n",
    "\n",
    "# Function to extract patches\n",
    "def extract_patches(hyperspectral_cube, label_map, patch_size=32):\n",
    "    patches = []\n",
    "    labels = []\n",
    "    height, width, spectral_bands = hyperspectral_cube.shape\n",
    "\n",
    "    for i in range(0, height - patch_size + 1, patch_size // 2):  # Sliding window with 50% overlap\n",
    "        for j in range(0, width - patch_size + 1, patch_size // 2):\n",
    "            patch = hyperspectral_cube[i:i+patch_size, j:j+patch_size, :]\n",
    "            label_patch = label_map[i:i+patch_size, j:j+patch_size]\n",
    "\n",
    "            # Only include patches with at least one annotated pixel\n",
    "            if np.any(label_patch != -1):  # -1 indicates unannotated pixels\n",
    "                patches.append(patch)\n",
    "                labels.append(label_patch)\n",
    "\n",
    "    return np.array(patches, dtype=np.float32), np.array(labels, dtype=np.float32)  # Reduce precision\n",
    "\n",
    "# Lists to store data\n",
    "X = []  # Input data (patches of hyperspectral cubes)\n",
    "Y = []  # Labels (patches of label maps)\n",
    "\n",
    "# Process each core in smaller batches\n",
    "batch_size = 5  # Process 5 cores at a time\n",
    "for i in range(0, len(core_names), batch_size):\n",
    "    batch_cores = core_names[i:i + batch_size]\n",
    "    batch_X = []\n",
    "    batch_Y = []\n",
    "\n",
    "    for core_name in batch_cores:\n",
    "        mat_path = os.path.join(data_location, core_name + \".npz\")\n",
    "        img_path = os.path.join(annotation_location, core_name + \".png\")\n",
    "\n",
    "        # Load hyperspectral data\n",
    "        data = np.load(mat_path)\n",
    "        spectra = data[\"spectra\"].astype(np.float32)  # Reduce precision\n",
    "        wavenumbers = data[\"wavenumbers\"]\n",
    "        indices = data[\"indices\"].flatten()\n",
    "\n",
    "        # Load annotated image\n",
    "        annotated_img = Image.open(img_path)\n",
    "        annotated_img = np.array(annotated_img)\n",
    "\n",
    "        # Get spatial dimensions\n",
    "        ypixels, xpixels = annotated_img.shape[:2]\n",
    "\n",
    "        # Convert indices to (row, col) positions\n",
    "        rows = indices % ypixels\n",
    "        cols = indices // ypixels\n",
    "\n",
    "        # Create a 3D hyperspectral cube\n",
    "        hyperspectral_cube = np.zeros((ypixels, xpixels, spectra.shape[1]), dtype=np.float32)  # Reduce precision\n",
    "        hyperspectral_cube[rows, cols, :] = spectra  # Fill the cube with spectra\n",
    "\n",
    "\n",
    "\n",
    "    # Append batch data to main lists\n",
    "    X.append(np.concatenate(batch_X, axis=0))\n",
    "    Y.append(np.concatenate(batch_Y, axis=0))\n",
    "\n",
    "    # Clear batch variables\n",
    "    del batch_X, batch_Y\n",
    "    gc.collect()\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.concatenate(X, axis=0)  # Shape: [num_patches, patch_size, patch_size, spectral_bands]\n",
    "Y = np.concatenate(Y, axis=0)  # Shape: [num_patches, patch_size, patch_size]\n",
    "\n",
    "# Print shapes\n",
    "print(\"Hyperspectral patches shape:\", X.shape)\n",
    "print(\"Label patches shape:\", Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for gpt 3D pca\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pca(spectral_data, n_components=80):\n",
    "    \"\"\"\n",
    "    Apply PCA for noise reduction on a hyperspectral image or spectral data.\n",
    "\n",
    "    Parameters:\n",
    "    spectral_data (numpy array): 2D array (N, C) or 3D array (H, W, C) of spectral data\n",
    "    n_components (int): Number of principal components to retain\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Denoised spectral data with the same shape as input\n",
    "    \"\"\"\n",
    "    # Check input shape\n",
    "    if spectral_data.ndim == 3:  # If input is (H, W, C)\n",
    "        H, W, C = spectral_data.shape\n",
    "        reshaped_spectra = spectral_data.reshape(-1, C)  # Flatten to (H*W, C)\n",
    "    elif spectral_data.ndim == 2:  # If input is (N, C)\n",
    "        reshaped_spectra = spectral_data\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid input shape {spectral_data.shape}, expected 2D (N, C) or 3D (H, W, C)\")\n",
    "\n",
    "    # Compute mean spectrum\n",
    "    mean_spectra = np.mean(reshaped_spectra, axis=0)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "    try:\n",
    "        transformed = pca_model.fit_transform(reshaped_spectra - mean_spectra)  # Center data\n",
    "        denoised = pca_model.inverse_transform(transformed) + mean_spectra  # Reconstruct\n",
    "    except Exception as e:\n",
    "        print(f\"Error during PCA transformation: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Ensure the result is a valid NumPy array\n",
    "    if not isinstance(denoised, np.ndarray):\n",
    "        print(f\"PCA output is not a valid numpy array. Type: {type(denoised)}\")\n",
    "        return None\n",
    "\n",
    "    # Reshape back if input was 3D\n",
    "    if spectral_data.ndim == 3:\n",
    "        return denoised.reshape(H, W, -1)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "\n",
    "def preprocess(spectral_images, wavenumbers):\n",
    "    \"\"\"\n",
    "    Preprocess hyperspectral images with memory-efficient noise reduction and filtering.\n",
    "\n",
    "    Parameters:\n",
    "    spectral_images (numpy array): 4D array (N, H, W, C)\n",
    "    wavenumbers (numpy array): 1D array of spectral bands\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Preprocessed spectral images with reduced spectral channels\n",
    "    \"\"\"\n",
    "    N, H, W, C = spectral_images.shape\n",
    "    final_images = []\n",
    "\n",
    "    for i in range(N):  # Process one image at a time\n",
    "        image = spectral_images[i].astype(np.float16)  # Convert to float16 to save memory\n",
    "\n",
    "        # 1. Quality filtering based on Amide I Band (1600 - 1700 cm⁻¹)\n",
    "        amide_band_indices = np.where((wavenumbers >= 1600) & (wavenumbers <= 1700))[0]\n",
    "        amide_spectra = np.max(image[:, :, amide_band_indices], axis=-1)\n",
    "\n",
    "        # Retain pixels with valid absorbance (0.1 to 2)\n",
    "        valid_mask = (amide_spectra >= 0.1) & (amide_spectra <= 2)\n",
    "        image[~valid_mask, :] = 0  # Zero out invalid pixels\n",
    "\n",
    "        # 2. Remove paraffin wax regions\n",
    "        valid_wavenumbers = np.where(\n",
    "            ((wavenumbers >= 1000) & (wavenumbers <= 1319)) | \n",
    "            ((wavenumbers >= 1481) & (wavenumbers <= 1769)) |\n",
    "            ((wavenumbers >= 2986) & (wavenumbers <= 3569))\n",
    "        )[0]\n",
    "\n",
    "        # Apply filtering\n",
    "        image = image[:, :, valid_wavenumbers]\n",
    "        filtered_wavenumbers = wavenumbers[valid_wavenumbers]\n",
    "\n",
    "        # 3. Compute First Derivative Using Savitzky-Golay Filter (Apply Along Last Axis)\n",
    "        window_size = 19  \n",
    "        poly_order = 4\n",
    "        for x in range(H):\n",
    "            for y in range(W):\n",
    "                image[x, y, :] = savgol_filter(\n",
    "                    image[x, y, :], window_length=window_size, polyorder=poly_order, deriv=1, \n",
    "                    mode=\"nearest\"\n",
    "                )\n",
    "\n",
    "        # 4. Remove Edge Regions Influenced by Derivatization\n",
    "        valid_end_regions = np.where(\n",
    "            ((filtered_wavenumbers >= 1019) & (filtered_wavenumbers <= 1300)) |\n",
    "            ((filtered_wavenumbers >= 1500) & (filtered_wavenumbers <= 1750)) |\n",
    "            ((filtered_wavenumbers >= 3005) & (filtered_wavenumbers <= 3550))\n",
    "        )[0]\n",
    "\n",
    "        final_image = image[:, :, valid_end_regions]\n",
    "        final_images.append(final_image)  # Store processed image\n",
    "\n",
    "    # Convert list back to numpy array\n",
    "    return np.array(final_images), filtered_wavenumbers[valid_end_regions]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT label and spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define constants\n",
    "TARGET_H, TARGET_W = 256, 256  # Standardized spatial size\n",
    "DTYPE = np.float32  # Use lower precision\n",
    "\n",
    "def pad_or_crop(image, target_size=(256, 256), fill_value=0):\n",
    "    \"\"\"\n",
    "    Resize an image to a fixed size by padding or cropping.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    target_h, target_w = target_size\n",
    "\n",
    "    # Initialize a blank canvas\n",
    "    new_image = np.full((target_h, target_w, image.shape[-1]), fill_value, dtype=image.dtype)\n",
    "\n",
    "    # Determine cropping or centering\n",
    "    crop_h, crop_w = min(h, target_h), min(w, target_w)\n",
    "    start_h, start_w = (h - crop_h) // 2, (w - crop_w) // 2\n",
    "    target_start_h, target_start_w = (target_h - crop_h) // 2, (target_w - crop_w) // 2\n",
    "\n",
    "    # Crop and place in the center\n",
    "    new_image[target_start_h:target_start_h + crop_h, target_start_w:target_start_w + crop_w] = \\\n",
    "        image[start_h:start_h + crop_h, start_w:start_w + crop_w]\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# Define file locations\n",
    "data_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\DataCube\\DataCube_npz\"\n",
    "annotation_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\overlay\"\n",
    "\n",
    "core_names = [\n",
    "    \"A12\",\"C10\", \"C16\"\n",
    "    # , \"C5\", \"C8\",\n",
    "    # \"D5\", \"D7\", \"D8\", \"D9\", \"E7\", \"E8\", \"F5\", \"F7\", \"F8\",\n",
    "    # \"G6\", \"H7\", \"H10\", \"H9\", \"I3\", \"I5\", \"A14\", \"I7\", \"B9\", \"I10\",\n",
    "    # \"K1\", \"K10\", \"K6\", \"K9\", \"B11\", \"L10\", \"L2\", \"L3\",\n",
    "    # \"M1\", \"M3\", \"M4\", \"M6\", \"M9\", \"M10\", \"M11\", \"M13\"\n",
    "]\n",
    "\n",
    "annotation_colours = {\n",
    "    \"red\": (255, 0, 0),      # Cancer\n",
    "    \"green\": (103, 193, 66), # Normal\n",
    "    \"orange\": (243, 143, 53),# Normal\n",
    "    \"purple\": (165, 55, 156) # Cancer\n",
    "}\n",
    "\n",
    "\n",
    "# Process each core ensuring uniform shape\n",
    "all_spectral_images = []\n",
    "all_label_masks = []\n",
    "\n",
    "for core_name in core_names:\n",
    "    mat_path = os.path.join(data_location, core_name + \".npz\")\n",
    "    img_path = os.path.join(annotation_location, core_name + \".png\")\n",
    "\n",
    "    data = np.load(mat_path)\n",
    "    spectra = data[\"spectra\"].astype(DTYPE)  # Convert early to lower precision\n",
    "    wavenumbers = data[\"wavenumbers\"]\n",
    "    indices = data[\"indices\"].flatten()\n",
    "\n",
    "    annotated_img = np.array(Image.open(img_path))\n",
    "    ypixels, xpixels = annotated_img.shape[:2]\n",
    "    spectral_channels = spectra.shape[1]\n",
    "\n",
    "    # Convert indices to (row, col) positions\n",
    "    rows = indices % ypixels  \n",
    "    cols = indices // ypixels\n",
    "\n",
    "    # Create empty spectral image grid and label mask\n",
    "    spectral_image = np.zeros((ypixels, xpixels, spectral_channels), dtype=DTYPE)\n",
    "\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    selected_spectra = np.array(selected_spectra, dtype=DTYPE)\n",
    "    selected_labels = np.array(selected_labels)\n",
    "\n",
    "    # Apply PCA for noise reduction\n",
    "    denoised_spectra = pca(selected_spectra)\n",
    "\n",
    "    # Create spatial mask\n",
    "    for i, (row, col) in enumerate(selected_positions):\n",
    "        spectral_image[row, col, :] = denoised_spectra[i]\n",
    "        label_mask[row, col] = selected_labels[i]\n",
    "\n",
    "    # Ensure uniform shape (256x256)\n",
    "    spectral_image = pad_or_crop(spectral_image, (TARGET_H, TARGET_W), fill_value=0)\n",
    "    label_mask = pad_or_crop(label_mask[..., np.newaxis], (TARGET_H, TARGET_W), fill_value=0)[..., 0]  # Remove extra channel\n",
    "\n",
    "    # Append results (or save to disk to free memory)\n",
    "    all_spectral_images.append(spectral_image)\n",
    "    all_label_masks.append(label_mask)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "all_spectral_images = np.array(all_spectral_images, dtype=DTYPE)\n",
    "all_label_masks = np.array(all_label_masks, dtype=np.uint8)\n",
    "\n",
    "# Print final shapes\n",
    "print(f\"Spectral Image Shape (for CNN input): {all_spectral_images.shape}\")  # (N, 256, 256, C)\n",
    "print(f\"Label Mask Shape: {all_label_masks.shape}\")  # (N, 256, 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Free memory before processing\n",
    "del selected_spectra, selected_labels, selected_positions, spectral_image, label_mask\n",
    "gc.collect()  # Force garbage collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "batch_size = 5  # Process only 5 images at a time (adjust if needed)\n",
    "X_list = []\n",
    "\n",
    "for i in range(0, len(all_spectral_images), batch_size):\n",
    "    batch = all_spectral_images[i:i + batch_size]  # Get batch\n",
    "    X_batch = preprocess(batch, wavenumbers)  # Process batch\n",
    "    X_list.append(X_batch)  # Store results\n",
    "    \n",
    "    # Free memory\n",
    "    del batch, X_batch\n",
    "    gc.collect()\n",
    "\n",
    "# Convert back to NumPy array\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "del X_list  # Free list\n",
    "gc.collect()\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for correct method\n",
    "# import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def pca_denoise(spectral_data, variance_threshold=0.99):\n",
    "    if spectral_data.ndim != 3:\n",
    "        raise ValueError(f\"Expected (H, W, C) shape, not {spectral_data.shape}\")\n",
    "\n",
    "    H, W, C = spectral_data.shape\n",
    "    reshaped_spectra = spectral_data.reshape(-1, C)  # Flatten to (H*W, C)\n",
    "\n",
    "    # Handle NaNs/Infs before PCA\n",
    "    reshaped_spectra = np.nan_to_num(reshaped_spectra)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=variance_threshold, whiten=True)\n",
    "    transformed = pca.fit_transform(reshaped_spectra)  # Auto-centers data\n",
    "    denoised = pca.inverse_transform(transformed)  # Reconstruct\n",
    "    \n",
    "    return denoised.reshape(H, W, C)  # Restore original shape\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(spectral_images, wavenumbers):\n",
    "    \"\"\"\n",
    "    Preprocess hyperspectral images with memory-efficient noise reduction and filtering.\n",
    "\n",
    "    Parameters:\n",
    "    spectral_images (numpy array): 4D array (N, H, W, C)\n",
    "    wavenumbers (numpy array): 1D array of spectral bands\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Preprocessed spectral images with reduced spectral channels\n",
    "    \"\"\"\n",
    "    N, H, W, C = spectral_images.shape\n",
    "    final_images = []\n",
    "\n",
    "    for i in range(N):  # Process one image at a time\n",
    "        image = spectral_images[i].astype(np.float16)  # Convert to float16 to save memory\n",
    "\n",
    "        # 1. Quality filtering based on Amide I Band (1600 - 1700 cm⁻¹)\n",
    "        amide_band_indices = np.where((wavenumbers >= 1600) & (wavenumbers <= 1700))[0]\n",
    "        amide_spectra = np.max(image[:, :, amide_band_indices], axis=-1)\n",
    "\n",
    "        # Retain pixels with valid absorbance (0.1 to 2)\n",
    "        valid_mask = (amide_spectra >= 0.1) & (amide_spectra <= 2)\n",
    "        image[~valid_mask, :] = 0  # Zero out invalid pixels\n",
    "\n",
    "        # 2. Remove paraffin wax regions\n",
    "        valid_wavenumbers = np.where(\n",
    "            ((wavenumbers >= 1000) & (wavenumbers <= 1319)) | \n",
    "            ((wavenumbers >= 1481) & (wavenumbers <= 1769)) |\n",
    "            ((wavenumbers >= 2986) & (wavenumbers <= 3569))\n",
    "        )[0]\n",
    "\n",
    "        # Apply filtering\n",
    "        image = image[:, :, valid_wavenumbers]\n",
    "        filtered_wavenumbers = wavenumbers[valid_wavenumbers]\n",
    "\n",
    "        # 3. Compute First Derivative Using Savitzky-Golay Filter (Apply Along Last Axis)\n",
    "        window_size = 19  \n",
    "        poly_order = 4\n",
    "        for x in range(H):\n",
    "            for y in range(W):\n",
    "                image[x, y, :] = savgol_filter(\n",
    "                    image[x, y, :], window_length=window_size, polyorder=poly_order, deriv=1, \n",
    "                    mode=\"nearest\"\n",
    "                )\n",
    "\n",
    "        # 4. Remove Edge Regions Influenced by Derivatization\n",
    "        valid_end_regions = np.where(\n",
    "            ((filtered_wavenumbers >= 1019) & (filtered_wavenumbers <= 1300)) |\n",
    "            ((filtered_wavenumbers >= 1500) & (filtered_wavenumbers <= 1750)) |\n",
    "            ((filtered_wavenumbers >= 3005) & (filtered_wavenumbers <= 3550))\n",
    "        )[0]\n",
    "\n",
    "        final_image = image[:, :, valid_end_regions]\n",
    "        final_images.append(final_image)  # Store processed image\n",
    "\n",
    "    # Convert list back to numpy array\n",
    "    return np.array(final_images), filtered_wavenumbers[valid_end_regions]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECT CONCEPT \n",
    "\n",
    "\n",
    "\n",
    "def center_zero_pad(image, target_size=(256, 256)):\n",
    "    h, w, c = image.shape\n",
    "    target_h, target_w = target_size\n",
    "\n",
    "    # Find non-zero (or non-background) pixels\n",
    "    non_zero_rows = np.where(np.any(image != 0, axis=(1, 2)))[0]\n",
    "    non_zero_cols = np.where(np.any(image != 0, axis=(0, 2)))[0]\n",
    "\n",
    "    # Get bounding box of the core region\n",
    "    min_r, max_r = non_zero_rows[0], non_zero_rows[-1]\n",
    "    min_c, max_c = non_zero_cols[0], non_zero_cols[-1]\n",
    "\n",
    "    # Crop to bounding box\n",
    "    cropped_image = image[min_r:max_r+1, min_c:max_c+1, :]\n",
    "\n",
    "    # Get new dimensions after cropping\n",
    "    h_cropped, w_cropped, _ = cropped_image.shape\n",
    "\n",
    "    # Create a blank canvas filled with zeros\n",
    "    padded_image = np.zeros((target_h, target_w, c), dtype=np.float32)\n",
    "\n",
    "    # Compute new centering offsets\n",
    "    start_h = (target_h - h_cropped) // 2\n",
    "    start_w = (target_w - w_cropped) // 2\n",
    "\n",
    "    # Place the cropped image in the center\n",
    "    padded_image[start_h:start_h + h_cropped, start_w:start_w + w_cropped, :] = cropped_image\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "data_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\DataCube\\DataCube_npz\"\n",
    "annotation_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\overlay\"\n",
    "\n",
    "core_names = [\n",
    "    \"A12\",\"C10\", \n",
    "    \"C16\"\n",
    "    , \"C5\", \"C8\",\n",
    "    \"D5\", \"D7\", \"D8\", \"D9\", \"E7\", \"E8\", \"F5\", \"F7\", \"F8\",\n",
    "    \"G6\", \"H7\", \"H10\", \"H9\", \"I3\", \"I5\", \"A14\", \"I7\", \"B9\", \"I10\",\n",
    "    \"K1\", \"K10\", \"K6\", \"K9\", \"B11\", \"L10\", \"L2\", \"L3\",\n",
    "    \"M1\", \"M3\", \"M4\", \n",
    "    \"M6\", \"M9\", \"M10\", \"M11\", \"M13\"\n",
    "]\n",
    "\n",
    "annotation_colours = {\n",
    "    \"red\": (255, 0, 0),      # Cancer\n",
    "    \"green\": (103, 193, 66), # Normal\n",
    "    \"orange\": (243, 143, 53),# Normal\n",
    "    \"purple\": (165, 55, 156) # Cancer\n",
    "}\n",
    "\n",
    "# Lists to store data\n",
    "X = []  # Input data \n",
    "\n",
    "for core_name in core_names:\n",
    "    mat_path = os.path.join(data_location, core_name + \".npz\")\n",
    "    img_path = os.path.join(annotation_location, core_name + \".png\")\n",
    "\n",
    "    # Load hyperspectral data\n",
    "    data = np.load(mat_path)\n",
    "    spectra = data[\"spectra\"] #.astype(np.float32)  # Reduce precision\n",
    "    wavenumbers = data[\"wavenumbers\"]\n",
    "    indices = data[\"indices\"].flatten()\n",
    "\n",
    "    # Load annotated image\n",
    "    annotated_img = Image.open(img_path)\n",
    "    annotated_img = np.array(annotated_img)\n",
    "\n",
    "    # Get spatial dimensions\n",
    "    ypixels, xpixels = annotated_img.shape[:2]\n",
    "\n",
    "    # Convert indices to (row, col) positions\n",
    "    rows = indices % ypixels\n",
    "    cols = indices // ypixels\n",
    "\n",
    "    # Create a 3D hyperspectral cube\n",
    "    spectral_image = np.zeros((ypixels, xpixels, spectra.shape[1]), dtype=np.float32)  # Reduce precision\n",
    "    spectral_image[rows, cols, :] = spectra  # Fill the cube with spectra\n",
    "    # print(spectral_image.shape) # should be (H, W, C)\n",
    "    spectral_image = center_zero_pad(spectral_image)\n",
    "    # print(spectral_image.shape) # should be (H, W, C)\n",
    "   \n",
    "    # plot figure of spectral image for amide 1 band   \n",
    "    # plt.figure()\n",
    "    # plt.imshow(spectral_image[:,:,365]) \n",
    "    # plt.show()\n",
    "    clean_spectral_image = pca_denoise(spectral_image)\n",
    "    # print(clean_spectral_image.shape) # should be (H, W, C)\n",
    "\n",
    "# # Append batch data to main lists\n",
    "# X.append(np.concatenate(batch_X, axis=0))\n",
    "# Y.append(np.concatenate(batch_Y, axis=0))\n",
    "\n",
    "# # Clear batch variables\n",
    "# del batch_X, batch_Y\n",
    "# gc.collect()\n",
    "\n",
    "# # Convert lists to NumPy arrays\n",
    "# X = np.concatenate(X, axis=0)  # Shape: [num_patches, patch_size, patch_size, spectral_bands]\n",
    "# Y = np.concatenate(Y, axis=0)  # Shape: [num_patches, patch_size, patch_size]\n",
    "\n",
    "# Print shapes\n",
    "# print(\"Hyperspectral patches shape:\", X.shape)\n",
    "# print(\"Label patches shape:\", Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## !Curr method\n",
    "# def overlay_extracted_pixels(img, extracted_rows, extracted_cols):\n",
    "#     overlay_img = img.copy()\n",
    "#     overlay_img = overlay_img[:,:,:3]\n",
    "#     for r, c in zip(extracted_rows, extracted_cols):\n",
    "#         overlay_img[r, c] = (255, 192, 203)  # pink overlay for detected pixels\n",
    "\n",
    "#     # Display overlay image\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.imshow(overlay_img)\n",
    "#     plt.title(f\"Overlay of Detected Spectra for {core_name}\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Find annotated pixels\n",
    "# def find_colour_positions(colour):\n",
    "#     return set(zip(*np.where(\n",
    "#         (annotated_img[:, :, 0] == colour[0]) & \n",
    "#         (annotated_img[:, :, 1] == colour[1]) &\n",
    "#         (annotated_img[:, :, 2] == colour[2])\n",
    "#     )))\n",
    "    \n",
    "# # Define file locations\n",
    "# data_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\DataCube\\DataCube_npz\"\n",
    "# annotation_location = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\overlay\"\n",
    "\n",
    "# core_names = [\n",
    "#     \"A12\",\"C10\", \"C16\", \"C5\", \"C8\",\n",
    "#     \"D5\", \"D7\", \"D8\", \"D9\", \"E7\", \"E8\", \"F5\", \"F7\", \"F8\",\n",
    "#     \"G6\", \"H7\", \"H10\", \"H9\", \"I3\", \"I5\", \"A14\", \"I7\", \"B9\", \"I10\",\n",
    "#     \"K1\", \"K10\", \"K6\", \"K9\", \"B11\", \"L10\", \"L2\", \"L3\",\n",
    "#     \"M1\", \"M3\", \"M4\", \"M6\", \"M9\", \"M10\", \"M11\", \"M13\"\n",
    "# ]\n",
    "\n",
    "# annotation_colours = {\n",
    "#     \"red\": (255, 0, 0),\n",
    "#     \"green\": (103, 193, 66),\n",
    "#     \"orange\":(243,143,53),\n",
    "#     \"purple\":(165,55,156)\n",
    "# }\n",
    "\n",
    "# all_spectra = []\n",
    "# count_spectra = []\n",
    "# Y = []\n",
    "    \n",
    "# # Process each core\n",
    "# for core_name in core_names:\n",
    "#     mat_path = os.path.join(data_location, core_name + \".npz\")\n",
    "#     img_path = os.path.join(annotation_location, core_name + \".png\")\n",
    "\n",
    "#     data = np.load(mat_path)\n",
    "\n",
    "#     spectra = data[\"spectra\"]\n",
    "#     wavenumbers = data[\"wavenumbers\"]\n",
    "#     indices = data[\"indices\"].flatten()\n",
    "\n",
    "#     annotated_img = Image.open(img_path)\n",
    "#     annotated_img = np.array(annotated_img)\n",
    "#     # annotated_img = cv2.cvtcolourr(cv2.imread(img_path), cv2.colourr_BGR2RGB) - faster because don't need to convert each from bgr2rgb\n",
    "#     # print(annotated_img.shape)\n",
    "    \n",
    "#     # Fix dimensions (Swapped to match MATLAB)\n",
    "#     ypixels, xpixels = annotated_img.shape[:2]\n",
    "#     # ypixels, xpixels = annotated_img.shape[0], annotated_img.shape[1]\n",
    "\n",
    "#     # Convert indices to (row, col) positions\n",
    "#     rows = indices % ypixels  \n",
    "#     cols = indices // ypixels\n",
    "\n",
    "#     # Convert to NumPy array for consistency\n",
    "#     pixel_positions = np.column_stack((rows, cols))  \n",
    "#     # print(len(pixel_positions))\n",
    "\n",
    "#     red_positions = find_colour_positions(annotation_colours[\"red\"])\n",
    "#     purple_positions = find_colour_positions(annotation_colours[\"purple\"])\n",
    "#     green_positions = find_colour_positions(annotation_colours[\"green\"])\n",
    "#     orange_positions = find_colour_positions(annotation_colours[\"orange\"])\n",
    "    \n",
    "#     core_spectra = []\n",
    "#     extracted_rows = []\n",
    "#     extracted_cols = []\n",
    "            \n",
    "#     for i in range(len(pixel_positions)):\n",
    "#         row, col = pixel_positions[i]\n",
    "#         if i >= spectra.shape[0]:  # Prevent index out of bounds\n",
    "#             continue  \n",
    "\n",
    "#         if (row, col) in red_positions or (row, col) in purple_positions:\n",
    "#             core_spectra.append(spectra[i])\n",
    "#             extracted_rows.append(row)\n",
    "#             extracted_cols.append(col)\n",
    "#         elif (row, col) in green_positions or (row, col) in orange_positions:\n",
    "#             core_spectra.append(spectra[i])\n",
    "#             extracted_rows.append(row)\n",
    "#             extracted_cols.append(col)\n",
    "            \n",
    "\n",
    "#     # Convert to numpy array\n",
    "#     core_spectra = np.array(core_spectra)\n",
    "#     # pca\n",
    "#     clean_spectra = pca(core_spectra)\n",
    "#     all_spectra.append(clean_spectra)\n",
    "    \n",
    "#     count_spectra.append((core_name, clean_spectra.shape[0]))\n",
    " \n",
    "#     # Overlay detected pixels\n",
    "#     # overlay_extracted_pixels(annotated_img, extracted_rows, extracted_cols)\n",
    "# # Convert list to NumPy arrays\n",
    "# all_spectra = [np.array(core, dtype=np.float32) for core in all_spectra]\n",
    "\n",
    "# # print(all_spectra)\n",
    "# # Sort and plot core sizes\n",
    "# count_spectra.sort(key=lambda x: x[1])\n",
    "# core_names_sorted, pixel_counts_sorted = zip(*count_spectra)\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(core_names_sorted, pixel_counts_sorted, colour=\"skyblue\")\n",
    "\n",
    "# min_annotated_pixels = pixel_counts_sorted[0]\n",
    "# # Highlight the core with the minimum pixel count\n",
    "# min_core_index = pixel_counts_sorted.index(min_annotated_pixels)\n",
    "# plt.bar(core_names_sorted[min_core_index], pixel_counts_sorted[min_core_index], colour=\"red\", label=\"Min Core\")\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel(\"Core ID\")\n",
    "# plt.ylabel(\"Number of Annotated Pixels\")\n",
    "# plt.title(\"Number of Annotated Pixels per Core\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Minimum annotated pixels per core: {pixel_counts_sorted[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting .mat files to .npy files\n",
    "# training_path = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\processed-data\" \n",
    "\n",
    "# os.makedirs(training_path, exist_ok=True)\n",
    "\n",
    "# # Min_all_spectra is taking the minimum annotated pixels from all cores at random\n",
    "# min_all_spectra = []\n",
    "\n",
    "# for core in all_spectra:\n",
    "#     min_all_spectra.append(core[np.random.choice(core.shape[0],min_annotated_pixels, replace=False)])\n",
    "\n",
    "# min_all_spectra = np.array(min_all_spectra,dtype=np.float32) # potential change: reshape min_all_spectra to 2d from 3d ( N ,1478)\n",
    "\n",
    "# wavenumbers = wavenumbers.flatten()\n",
    "# X = preprocess(min_all_spectra, wavenumbers)\n",
    "# print(\"X shape\",X.shape) # want this to be (40, something, 558)\n",
    "\n",
    "# Y = []\n",
    "# csv_directory = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\BR20832.csv\"\n",
    "# df = pd.read_csv(csv_directory, usecols=[\"position\", \"type\"])\n",
    "\n",
    "# df[\"type\"] = df[\"type\"].str.lower().map({\"malignant\": 1, \"normal\": 0, \"nat\": 0})\n",
    "# label_dict = df.set_index(\"position\")[\"type\"].to_dict()\n",
    "\n",
    "# for core in core_names:\n",
    "#    Y.append(label_dict.get(core))\n",
    "# # print(Y)\n",
    "# print(\"Y shape\",len(Y))\n",
    "\n",
    "\n",
    "# # Save as .npz files\n",
    "# training_data_path = os.path.join(training_path, 'training.npz')\n",
    "# np.savez_compressed(training_data_path, X=X, Y=Y)\n",
    "\n",
    "# print(\"Saved to training.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# core_names = [\n",
    "#     'L1','I8','H4','E6','C11','F6','F9','I6','M7','M8'\n",
    "# ]\n",
    "\n",
    "# annotation_colourrs = {\n",
    "#     \"red\": (255, 0, 0),\n",
    "#     \"green\": (103, 193, 66),\n",
    "#     \"orange\":(243,143,53),\n",
    "#     \"purple\":(165,55,156)\n",
    "# }\n",
    "\n",
    "# all_spectra = []\n",
    "# count_spectra = []\n",
    "# Y = []\n",
    "    \n",
    "# # Process each core\n",
    "# for core_name in core_names:\n",
    "#     mat_path = os.path.join(data_location, core_name + \".npz\")\n",
    "#     img_path = os.path.join(annotation_location, core_name + \".png\")\n",
    "\n",
    "#     data = np.load(mat_path)\n",
    "\n",
    "#     spectra = data[\"spectra\"]\n",
    "#     wavenumbers = data[\"wavenumbers\"]\n",
    "#     indices = data[\"indices\"].flatten()\n",
    "\n",
    "#     annotated_img = Image.open(img_path)\n",
    "#     annotated_img = np.array(annotated_img)\n",
    "#     # annotated_img = cv2.cvtcolour(cv2.imread(img_path), cv2.colour_BGR2RGB) - faster because don't need to convert each from bgr2rgb\n",
    "#     # print(annotated_img.shape)\n",
    "    \n",
    "#     # Fix dimensions (Swapped to match MATLAB)\n",
    "#     ypixels, xpixels = annotated_img.shape[:2]\n",
    "#     # ypixels, xpixels = annotated_img.shape[0], annotated_img.shape[1]\n",
    "\n",
    "#     # Convert indices to (row, col) positions\n",
    "#     rows = indices % ypixels  \n",
    "#     cols = indices // ypixels\n",
    "\n",
    "#     # Convert to NumPy array for consistency\n",
    "#     pixel_positions = np.column_stack((rows, cols))  \n",
    "#     # print(len(pixel_positions))\n",
    "\n",
    "#     core_spectra = []\n",
    "#     extracted_rows = []\n",
    "#     extracted_cols = []\n",
    "            \n",
    "#     for i in range(len(pixel_positions)):\n",
    "#         row, col = pixel_positions[i]\n",
    "#         if i >= spectra.shape[0]:  # Prevent index out of bounds\n",
    "#             continue  \n",
    "\n",
    "#         if (row, col) in red_positions or (row, col) in purple_positions:\n",
    "#             core_spectra.append(spectra[i])\n",
    "#             extracted_rows.append(row)\n",
    "#             extracted_cols.append(col)\n",
    "#         elif (row, col) in green_positions or (row, col) in orange_positions:\n",
    "#             core_spectra.append(spectra[i])\n",
    "#             extracted_rows.append(row)\n",
    "#             extracted_cols.append(col)\n",
    "            \n",
    "\n",
    "#     # Convert to numpy array\n",
    "#     core_spectra = np.array(core_spectra)\n",
    "#     # pca\n",
    "#     clean_spectra = pca(core_spectra)\n",
    "#     all_spectra.append(clean_spectra)\n",
    "    \n",
    "#     count_spectra.append((core_name, clean_spectra.shape[0]))\n",
    " \n",
    "#     # Overlay detected pixels\n",
    "#     # overlay_extracted_pixels(annotated_img, extracted_rows, extracted_cols)\n",
    "# # Convert list to NumPy arrays\n",
    "# all_spectra = [np.array(core, dtype=np.float32) for core in all_spectra]\n",
    "\n",
    "# # print(all_spectra)\n",
    "# # Sort and plot core sizes\n",
    "# count_spectra.sort(key=lambda x: x[1])\n",
    "# core_names_sorted, pixel_counts_sorted = zip(*count_spectra)\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(core_names_sorted, pixel_counts_sorted, colour=\"skyblue\")\n",
    "\n",
    "# min_annotated_pixels = pixel_counts_sorted[0]\n",
    "# # Highlight the core with the minimum pixel count\n",
    "# min_core_index = pixel_counts_sorted.index(min_annotated_pixels)\n",
    "# plt.bar(core_names_sorted[min_core_index], pixel_counts_sorted[min_core_index], colour=\"red\", label=\"Min Core\")\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel(\"Core ID\")\n",
    "# plt.ylabel(\"Number of Annotated Pixels\")\n",
    "# plt.title(\"Number of Annotated Pixels per Core\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Minimum annotated pixels per core: {pixel_counts_sorted[0]}\")\n",
    "\n",
    "# # Converting .mat files to .npy files\n",
    "# testing_path = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\processed-data\" \n",
    "\n",
    "# os.makedirs(testing_path, exist_ok=True)\n",
    "\n",
    "# # Min_all_spectra is taking the minimum annotated pixels from all cores at random\n",
    "# min_all_spectra = []\n",
    "\n",
    "# for core in all_spectra:\n",
    "#     min_all_spectra.append(core[np.random.choice(core.shape[0],min_annotated_pixels, replace=False)])\n",
    "\n",
    "# min_all_spectra = np.array(min_all_spectra,dtype=np.float32) # potential change: reshape min_all_spectra to 2d from 3d ( N ,1478)\n",
    "\n",
    "# wavenumbers = wavenumbers.flatten()\n",
    "# X = preprocess(min_all_spectra, wavenumbers)\n",
    "# print(\"X shape\",X.shape) # want this to be (40, something, 558)\n",
    "\n",
    "# Y = []\n",
    "# df = pd.read_csv(csv_directory, usecols=[\"position\", \"type\"])\n",
    "\n",
    "# df[\"type\"] = df[\"type\"].str.lower().map({\"malignant\": 1, \"normal\": 0, \"nat\": 0})\n",
    "# label_dict = df.set_index(\"position\")[\"type\"].to_dict()\n",
    "\n",
    "# for core in core_names:\n",
    "#    Y.append(label_dict.get(core))\n",
    "# # print(Y)\n",
    "# print(\"Y shape\",len(Y))\n",
    "\n",
    "\n",
    "# # Save as .npz files\n",
    "# testing_data_path = os.path.join(testing_path, 'testing.npz')\n",
    "# np.savez_compressed(testing_data_path, X=X, Y=Y)\n",
    "\n",
    "# print(\"Saved to testing.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_path = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\processed-data\\training.npz\" \n",
    "# testing_path  = r\"C:\\Users\\Edmund Chia\\Desktop\\HSI-cancer-fyp\\processed-data\\testing.npz\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# data = np.load(training_path, allow_pickle=True)\n",
    "# X = data[\"X\"]\n",
    "# Y = data[\"Y\"]\n",
    "\n",
    "# # print(X)\n",
    "# # print(Y)\n",
    "\n",
    "# # Define a 1D CNN for Spectral Data\n",
    "# class SpectralCNN(nn.Module):\n",
    "#     def __init__(self, input_dim=558, num_classes=2):\n",
    "#         super(SpectralCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=7, stride=1, padding=3)\n",
    "#         self.bn1 = nn.BatchNorm1d(32)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn2 = nn.BatchNorm1d(64)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm1d(128)\n",
    "#         self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # Pooling over spectral dimension\n",
    "#         self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.bn1(self.conv1(x)))\n",
    "#         x = torch.relu(self.bn2(self.conv2(x)))\n",
    "#         x = torch.relu(self.bn3(self.conv3(x)))\n",
    "#         x = self.global_avg_pool(x).squeeze(-1)  # Global Average Pooling\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# class SpectraDataset(Dataset):\n",
    "#     def __init__(self, X, Y):\n",
    "#         self.data = []\n",
    "#         self.labels = []\n",
    "        \n",
    "#         for i, spectra in enumerate(X):\n",
    "#             num_pixels = spectra.shape[0]\n",
    "#             self.data.append(torch.tensor(spectra, dtype=torch.float32))  # Store spectra\n",
    "#             self.labels.extend([Y[i]] * num_pixels)  # Repeat label for each pixel\n",
    "\n",
    "#         self.data = torch.cat(self.data, dim=0)  # Stack all spectra\n",
    "#         self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data[idx].unsqueeze(0), self.labels[idx]  # Add channel dimension\n",
    "\n",
    "\n",
    "# # Convert X, Y to Dataset\n",
    "# dataset = SpectraDataset(X, Y)\n",
    "# train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# # Initialize model, loss function, optimizer\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = SpectralCNN().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 20\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for batch_X, batch_Y in train_loader:\n",
    "#         batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = criterion(outputs, batch_Y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
